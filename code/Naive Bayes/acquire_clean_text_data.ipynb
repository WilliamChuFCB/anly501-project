{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad687e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tweepy\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import collections\n",
    "from langdetect import detect\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = open(\"api-keys.json\")\n",
    "input=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79031037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# GET STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# INITALIZE STEMMER+LEMITZIZER+SIA\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0ec0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD KEYS INTO API\n",
    "consumer_key=input[\"consumer_key\"]    \n",
    "consumer_secret=input[\"consumer_secret\"]    \n",
    "access_token=input[\"access_token\"]    \n",
    "access_token_secret=input[\"access_token_secret\"]    \n",
    "bearer_token=input[\"bearer_token\"]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "209e7b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tweepy.api.API object at 0x7f82a9d2f940>\n",
      "monk_digi\n"
     ]
    }
   ],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "print(api)\n",
    "print(api.verify_credentials().screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35270b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_more(query,tweets_num):\n",
    "    num_tweets_collected=0\n",
    "    searches=[]\n",
    "    while num_tweets_collected<tweets_num:\n",
    "        if len(searches)==0:\n",
    "            search_results = api.search_tweets(query,lang=\"en\", count=100)\n",
    "        else:\n",
    "            search_results = api.search_tweets(query,lang=\"en\", count=100,max_id=max_id_next)\n",
    "        num_tweets_collected+=len(search_results)\n",
    "        max_id_next=int(search_results[-1]._json[\"id_str\"])-1\n",
    "\n",
    "        for i in range(len(search_results)):\n",
    "            searches.append(search_results[i])\n",
    "    return(searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37d5f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sh_to_list(searches):\n",
    "    texts=[]\n",
    "    for i in range(len(searches)):\n",
    "        texts.append(searches[i]._json[\"text\"])\n",
    "    return texts\n",
    "sh_free_list=sh_to_list(sh_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcb04a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acquire data from twitter\n",
    "\n",
    "sh_free=search_more(\"freeway\",3000)\n",
    "sh_free_list=list(set(sh_to_list(sh_free)))\n",
    "sh_mtr=search_more(\"metro\",3000)\n",
    "sh_mtr_list=list(set(sh_to_list(sh_mtr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fc35ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the text data\n",
    "\n",
    "def clean_string(text):\n",
    "    #FILTER OUT UNWANTED CHAR\n",
    "    new_text=\"\"\n",
    "    keep=\" abcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "    for character in text:\n",
    "        if character.lower() in keep:\n",
    "            new_text+=character.lower()\n",
    "        else: \n",
    "            new_text+=\" \"\n",
    "    text=new_text\n",
    "\n",
    "    #FILTER OUT UNWANTED WORDS\n",
    "    new_text=\"\"\n",
    "    for word in nltk.tokenize.word_tokenize(text):\n",
    "        if word not in nltk.corpus.stopwords.words('english'):\n",
    "            #lemmatize \n",
    "            tmp=lemmatizer.lemmatize(word)\n",
    "            word=tmp\n",
    "            if len(word)>1:\n",
    "                if word in [\".\",\",\",\"!\",\"?\",\":\",\";\"]:\n",
    "                    #remove the last space\n",
    "                    new_text=new_text[0:-1]+word+\" \"\n",
    "                else: #add a space\n",
    "                    new_text+=word.lower()+\" \"\n",
    "    text=new_text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75f39bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sh_free_list)):\n",
    "    sh_free_list[i]=clean_string(sh_free_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a719c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sh_mtr_list)):\n",
    "    sh_mtr_list[i]=clean_string(sh_mtr_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f276fd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text    label\n",
      "0                            thinking cat named freeway  freeway\n",
      "1     keilor lodge heavy traffic bothways calder fre...  freeway\n",
      "2     lot going funniest though literally person hor...  freeway\n",
      "3     spanish lady corner selling fruit another sell...  freeway\n",
      "4     leftcoastbias last one bakersfield hyatt house...  freeway\n",
      "...                                                 ...      ...\n",
      "1855  mckbkb one really loved riding harley car rush...  freeway\n",
      "1856  rt smmirror upcoming play showcase event two g...  freeway\n",
      "1857  port melbourne heavy traffic citybound west ga...  freeway\n",
      "1858  galveston county 45 gulf freeway southbound fm...  freeway\n",
      "1859  ever since found way take street amp house fre...  freeway\n",
      "\n",
      "[1860 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "tmp1=[]\n",
    "for i in range(0,len(sh_free_list)):\n",
    "    tmp1.append([sh_free_list[i],\"freeway\"])\n",
    "df1=pd.DataFrame(tmp1)\n",
    "df1=df1.rename(columns={0: \"text\", 1: \"label\"})\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f100c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  label\n",
      "0     pdxfato hcp1hcp tinakotek true live west pdx m...  metro\n",
      "1     thad calton local metro school easily accessib...  metro\n",
      "2     bearnar33940319 hi please contact customer rel...  metro\n",
      "3     tylerdaisydog1 metro sport tuchel manager main...  metro\n",
      "4     rodentdetector brienn365 melissalogic17 nwarik...  metro\n",
      "...                                                 ...    ...\n",
      "1745  unsethled though said right completely true de...  metro\n",
      "1746  sure hope replacement jewish trumpcrimefamily ...  metro\n",
      "1747  elliotftbshirts brilliant metro easy enough tr...  metro\n",
      "1748  rt profcanderson footage made clear pelosi sch...  metro\n",
      "1749  rt sitetrend top metro area number startup new...  metro\n",
      "\n",
      "[1750 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "tmp2=[]\n",
    "for i in range(0,len(sh_mtr_list)):\n",
    "    tmp2.append([sh_mtr_list[i],\"metro\"])\n",
    "df2=pd.DataFrame(tmp2)\n",
    "df2=df2.rename(columns={0: \"text\", 1: \"label\"})\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8ba6c513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text    label\n",
      "0                            thinking cat named freeway  freeway\n",
      "1     keilor lodge heavy traffic bothways calder fre...  freeway\n",
      "2     lot going funniest though literally person hor...  freeway\n",
      "3     spanish lady corner selling fruit another sell...  freeway\n",
      "4     leftcoastbias last one bakersfield hyatt house...  freeway\n",
      "...                                                 ...      ...\n",
      "1745  unsethled though said right completely true de...    metro\n",
      "1746  sure hope replacement jewish trumpcrimefamily ...    metro\n",
      "1747  elliotftbshirts brilliant metro easy enough tr...    metro\n",
      "1748  rt profcanderson footage made clear pelosi sch...    metro\n",
      "1749  rt sitetrend top metro area number startup new...    metro\n",
      "\n",
      "[3610 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.concat([df1,df2])\n",
    "print(df)\n",
    "df.to_csv('free_mtr_text_data.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
