{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad687e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tweepy\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import collections\n",
    "from langdetect import detect\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = open(\"api-keys.json\")\n",
    "input=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79031037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# GET STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# INITALIZE STEMMER+LEMITZIZER+SIA\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ec0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD KEYS INTO API\n",
    "consumer_key=input[\"consumer_key\"]    \n",
    "consumer_secret=input[\"consumer_secret\"]    \n",
    "access_token=input[\"access_token\"]    \n",
    "access_token_secret=input[\"access_token_secret\"]    \n",
    "bearer_token=input[\"bearer_token\"]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "209e7b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tweepy.api.API object at 0x7fbee1c7cfd0>\n",
      "monk_digi\n"
     ]
    }
   ],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "print(api)\n",
    "print(api.verify_credentials().screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35270b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_more(query,tweets_num):\n",
    "    num_tweets_collected=0\n",
    "    searches=[]\n",
    "    while num_tweets_collected<tweets_num:\n",
    "        if len(searches)==0:\n",
    "            search_results = api.search_tweets(query,lang=\"en\", count=100)\n",
    "        else:\n",
    "            search_results = api.search_tweets(query,lang=\"en\", count=100,max_id=max_id_next)\n",
    "        num_tweets_collected+=len(search_results)\n",
    "        max_id_next=int(search_results[-1]._json[\"id_str\"])-1\n",
    "\n",
    "        for i in range(len(search_results)):\n",
    "            searches.append(search_results[i])\n",
    "    return(searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37d5f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sh_to_list(searches):\n",
    "    texts=[]\n",
    "    for i in range(len(searches)):\n",
    "        texts.append(searches[i]._json[\"text\"])\n",
    "    return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcb04a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acquire data from twitter\n",
    "\n",
    "sh_free=search_more(\"freeway\",3000)\n",
    "sh_free_list=list(set(sh_to_list(sh_free)))\n",
    "sh_mtr=search_more(\"metro\",3000)\n",
    "sh_mtr_list=list(set(sh_to_list(sh_mtr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fc35ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the text data\n",
    "\n",
    "def clean_string(text):\n",
    "    #FILTER OUT UNWANTED CHAR\n",
    "    new_text=\"\"\n",
    "    keep=\" abcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "    for character in text:\n",
    "        if character.lower() in keep:\n",
    "            new_text+=character.lower()\n",
    "        else: \n",
    "            new_text+=\" \"\n",
    "    text=new_text\n",
    "\n",
    "    #FILTER OUT UNWANTED WORDS\n",
    "    new_text=\"\"\n",
    "    for word in nltk.tokenize.word_tokenize(text):\n",
    "        if word not in nltk.corpus.stopwords.words('english'):\n",
    "            #lemmatize \n",
    "            tmp=lemmatizer.lemmatize(word)\n",
    "            word=tmp\n",
    "            if len(word)>1:\n",
    "                if word in [\".\",\",\",\"!\",\"?\",\":\",\";\"]:\n",
    "                    #remove the last space\n",
    "                    new_text=new_text[0:-1]+word+\" \"\n",
    "                else: #add a space\n",
    "                    new_text+=word.lower()+\" \"\n",
    "    text=new_text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75f39bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sh_free_list)):\n",
    "    sh_free_list[i]=clean_string(sh_free_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a719c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sh_mtr_list)):\n",
    "    sh_mtr_list[i]=clean_string(sh_mtr_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f276fd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text    label\n",
      "0     woman accused killing mother wednesday morning...  freeway\n",
      "1     people think taking train poor people train ex...  freeway\n",
      "2     natural history museum los angeles county 1975...  freeway\n",
      "3     fwt frreway message freeway team telegram hope...  freeway\n",
      "4                         ahhh drove freeway first time  freeway\n",
      "...                                                 ...      ...\n",
      "2497         nowplaying freeway tune http co qvgzclbgcu  freeway\n",
      "2498  alejando816 modot kc imagine freeway downtown ...  freeway\n",
      "2499  laverton north heavy traffic citybound prince ...  freeway\n",
      "2500  joel krueger freeway adviser called global chi...  freeway\n",
      "2501  someone say needed people believe oh never mon...  freeway\n",
      "\n",
      "[2502 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "tmp1=[]\n",
    "for i in range(0,len(sh_free_list)):\n",
    "    tmp1.append([sh_free_list[i],\"freeway\"])\n",
    "df1=pd.DataFrame(tmp1)\n",
    "df1=df1.rename(columns={0: \"text\", 1: \"label\"})\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f100c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  label\n",
      "0     jaredpolis kyleclark contrast former republica...  metro\n",
      "1     bluedemondegen following night saw rage machin...  metro\n",
      "2     tom glynn carney got meet 102 year old sa hero...  metro\n",
      "3     rt nicklima7 quarter rhode island top local el...  metro\n",
      "4     brewenor afkaduddy charliehustleco part jayhaw...  metro\n",
      "...                                                 ...    ...\n",
      "1941              notoriousdmm luke metro sugondeez nut  metro\n",
      "1942  wuhan back lockdown nearly three year first co...  metro\n",
      "1943  hispanic population metro atlanta doubled sinc...  metro\n",
      "1944  ct plan spend 12 billion improve train service...  metro\n",
      "1945  rt susanbolger delighted launch halloweenestac...  metro\n",
      "\n",
      "[1946 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "tmp2=[]\n",
    "for i in range(0,len(sh_mtr_list)):\n",
    "    tmp2.append([sh_mtr_list[i],\"metro\"])\n",
    "df2=pd.DataFrame(tmp2)\n",
    "df2=df2.rename(columns={0: \"text\", 1: \"label\"})\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ba6c513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text    label\n",
      "0     woman accused killing mother wednesday morning...  freeway\n",
      "1     people think taking train poor people train ex...  freeway\n",
      "2     natural history museum los angeles county 1975...  freeway\n",
      "3     fwt frreway message freeway team telegram hope...  freeway\n",
      "4                         ahhh drove freeway first time  freeway\n",
      "...                                                 ...      ...\n",
      "1941              notoriousdmm luke metro sugondeez nut    metro\n",
      "1942  wuhan back lockdown nearly three year first co...    metro\n",
      "1943  hispanic population metro atlanta doubled sinc...    metro\n",
      "1944  ct plan spend 12 billion improve train service...    metro\n",
      "1945  rt susanbolger delighted launch halloweenestac...    metro\n",
      "\n",
      "[4448 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.concat([df1,df2])\n",
    "print(df)\n",
    "df.to_csv('free_mtr_text_data.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
